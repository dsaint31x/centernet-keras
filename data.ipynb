{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from turtle import pos\n",
    "\n",
    "# https://docs.python.org/ko/3/library/xml.etree.elementtree.html\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# https://imgaug.readthedocs.io/en/latest/\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "# https://imgaug.readthedocs.io/en/latest/source/api_augmentables_bbs.html\n",
    "from imgaug.augmentables.bbs import BoundingBoxesOnImage\n",
    "\n",
    "\"\"\"\n",
    "imgaug.augmentables.bbs.BoundingBoxesOnImage(bounding_boxes, shape)\n",
    "    * bounding_boxes (list of imgaug.augmentables.bbs.BoundingBox)\n",
    "    List of bounding boxes on the image.\n",
    "    * shape (tuple of int or ndarray)\n",
    "    The shape of the image on which the objects are placed.\n",
    "    Either an image with shape (H,W,[C]) or a tuple denoting such an image shape.\n",
    "\"\"\"\n",
    "\n",
    "ia.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image preprocessing\n",
    "def preprocess_input(image):\n",
    "    image = np.array(image, dtype=np.float32)\n",
    "    \n",
    "    # ?\n",
    "    return image / 127.5 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_radius(size, min_iou=0.7):\n",
    "    \n",
    "    # image의 size가 input으로 들어감\n",
    "    h, w = size\n",
    "\n",
    "    # intersection\n",
    "    a1 = 1\n",
    "    b1 = -(h + w)\n",
    "    c1 = w * h * (1 - min_iou)\n",
    "    sq1 = np.sqrt(b1**2 - 4 * a1 * c1)\n",
    "    r1 = (-b1 + sq1) / 2\n",
    "\n",
    "    # subset\n",
    "    a2 = 4\n",
    "    b2 = -2 * (h + w)\n",
    "    c2 = w * h * (1 - min_iou)\n",
    "    sq2 = np.sqrt(b2**2 - 4 * a2 * c2)\n",
    "    r2 = (-b2 + sq2) / 2\n",
    "\n",
    "    # superset\n",
    "    a3 = 4 * min_iou\n",
    "    b3 = 2 * min_iou * (h + w)\n",
    "    c3 = (min_iou - 1) * h * w\n",
    "    sq3 = np.sqrt(b3**2 - 4 * a3 * c3)\n",
    "    r3 = (-b3 + sq3) / 2\n",
    "\n",
    "    return min(r1, r2, r3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-30\n",
      "60.00000000000001\n",
      "25.69046515733026\n",
      "27.84523257866513\n"
     ]
    }
   ],
   "source": [
    "w = 10\n",
    "h = 20\n",
    "min_iou = 0.7\n",
    "\n",
    "a1 = 1\n",
    "\n",
    "b1 = -(h + w)\n",
    "print(b1)\n",
    "\n",
    "c1 = w * h * (1 - min_iou)\n",
    "print(c1)\n",
    "\n",
    "sq1 = np.sqrt(b1**2 - 4 * a1 * c1)\n",
    "print(sq1)\n",
    "\n",
    "r1 = (-b1 + sq1) / 2\n",
    "print(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_gaussian(heatmap, center, radius, k=1):\n",
    "    diameter = 2 * radius + 1\n",
    "    gaussian = gaussian2D((diameter, diameter), diameter / 6)\n",
    "\n",
    "    x, y = int(center[0]), int(center[1])\n",
    "\n",
    "    h, w = heatmap.shape[0:2]\n",
    "\n",
    "    left, right = min(x, radius), min(w - x, radius + 1)\n",
    "    top, bottom = min(y, radius), min(h - y, radius + 1)\n",
    "\n",
    "    masked_heatmap = heatmap[y - top:y + bottom, x - left:x + right]\n",
    "    masked_gaussian = gaussian[radius - top:radius + bottom,\n",
    "                               radius - left:radius + right]\n",
    "\n",
    "    if min(masked_gaussian.shape) > 0 and min(masked_heatmap.shape) > 0:\n",
    "        np.maximum(masked_heatmap, masked_gaussian * k, out=masked_heatmap)\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian2D(shape, sigma=1):\n",
    "    h, w = [(ss - 1.) / 2. for ss in shape]\n",
    "    y, x = np.ogrid[-h:h + 1, -w:w + 1]\n",
    "\n",
    "    map_2d = np.exp(-(x * x + y * y) / (2 * sigma * sigma))\n",
    "    map_2d[map_2d < np.finfo(map_2d.dtype).eps * map_2d.max()] = 0\n",
    "\n",
    "    return map_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'static' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-2a1140719433>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mVOCDataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# VOC 2007은 20개의 class로 이루어져 있음.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Object가 있는 이미지 : 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-2a1140719433>\u001b[0m in \u001b[0;36mVOCDataset\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[1;33m@\u001b[0m\u001b[0mstatic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_data_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mdata_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'static' is not defined"
     ]
    }
   ],
   "source": [
    "class VOCDataset:\n",
    "    \n",
    "    # VOC 2007은 20개의 class로 이루어져 있음.\n",
    "\n",
    "    # Object가 있는 이미지 : 1\n",
    "    # Object가 없는 이미지 : -1\n",
    "    # 다른 Object와 같이 있는 경우 : 0\n",
    "\n",
    "    ID2LABEL = [\n",
    "        \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\",\n",
    "        \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\",\n",
    "        \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"\n",
    "    ]\n",
    "\n",
    "    def __init__(self, path, \n",
    "                 input_shape, \n",
    "                 data_file,\n",
    "                     batch_size,\n",
    "                     training=False,\n",
    "                     buffer_size=10,\n",
    "                     class_names=None,):\n",
    "        self.path = path\n",
    "\n",
    "        # input_shape = (512, 512)\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        self.data_file = data_file\n",
    "        self.batch_size = batch_size\n",
    "        self.training = training\n",
    "        self.buffer_size = buffer_size\n",
    "\n",
    "        # output shape = (128, 128)\n",
    "        self.output_shape = (input_shape[0] // 4, input_shape[1] // 4)\n",
    "\n",
    "        self.class_names = class_names if class_names else self.ID2LABEL\n",
    "        self.num_classes = len(self.class_names)\n",
    "        self.data_ids = self._get_data_id(data_file)\n",
    "        \n",
    "        \n",
    "        if len(self.data_ids) % self.batch_size != 0:\n",
    "            self.data_ids.extend(self.data_ids[:self.batch_size - (len(self.data_ids) % self.batch_size)]) \n",
    "\n",
    "        self.seq = None\n",
    "\n",
    "    @static\n",
    "    def _get_data_id(file):\n",
    "        data_list = []\n",
    "        with open(file) as f:\n",
    "            for line in tqdm(f, desc=\"loading the context of data_file ...\"):\n",
    "                # strip 함수를 써서 공백을 없앴다.\n",
    "                data_list.append(line.strip())\n",
    "\n",
    "        return data_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.getitem(idx)\n",
    "\n",
    "    def getitem(self, idx):\n",
    "        data_id = self.data_ids[idx]\n",
    "        image_file = self.path + f\"/JPEGImages/{data_id}.jpg\"\n",
    "        annot_file = self.path + f\"/Annotations/{data_id}.xml\"\n",
    "\n",
    "        # fetch raw data\n",
    "        if not os.path.exists(image_file):\n",
    "            raise ValueError(f\"{image_file} not exists\")\n",
    "        if not os.path.exists(annot_file):\n",
    "            raise ValueError(f\"{annot_file} not exists\")\n",
    "\n",
    "        # image load\n",
    "        image = cv2.imread(image_file)\n",
    "\n",
    "        # xml로부터 데이터를 parse\n",
    "        tree = ET.parse(open(annot_file))\n",
    "        root = tree.getroot()\n",
    "\n",
    "        boxes = []\n",
    "        cls_ids = []\n",
    "        for i, obj in enumerate(root.iter('object')):\n",
    "            difficult = 0\n",
    "            if obj.find('difficult') != None:\n",
    "                difficult = obj.find('difficult').text\n",
    "            cls = obj.find('name').text\n",
    "            if cls not in self.class_names or int(difficult) == 1:\n",
    "                continue\n",
    "            cls_id = self.class_names.index(cls)\n",
    "            xmlbox = obj.find('bndbox')\n",
    "\n",
    "            # Bounding box 좌표 가져오기\n",
    "            b = [\n",
    "                int(xmlbox.find('xmin').text),\n",
    "                int(xmlbox.find('ymin').text),\n",
    "                int(xmlbox.find('xmax').text),\n",
    "                int(xmlbox.find('ymax').text)\n",
    "            ]\n",
    "            boxes.append(b)\n",
    "            cls_ids.append(cls_id)\n",
    "\n",
    "        boxes = np.array(boxes, np.float32)\n",
    "        cls_ids = np.array(cls_ids, np.int32)\n",
    "\n",
    "        # image(ih, iw) -> image(h, w)\n",
    "        ih, iw, _ = image.shape\n",
    "        h, w = self.input_shape\n",
    "\n",
    "        if self.training:\n",
    "            if self.seq is None:\n",
    "\n",
    "                # https://imgaug.readthedocs.io/en/latest/source/examples_basics.html\n",
    "                self.seq = iaa.Sequential([\n",
    "                    iaa.Fliplr(0.5),\n",
    "                    iaa.Resize({\n",
    "                        \"height\": (0.7, 1.3),\n",
    "                        \"weight\": (0.7, 1.3)\n",
    "                    }),\n",
    "                    iaa.Resize((.25, 2.)),\n",
    "                    iaa.PadToFixedSize(width=w, height=h, pad_cval=128),\n",
    "                    iaa.CropToFixedSize(width=w, height=h),\n",
    "                    iaa.MultiplyHue((0.5, 1.5)),\n",
    "                    iaa.MultiplySaturation((0.5, 1.5)),\n",
    "                    iaa.MultiplyBrightness((0.5, 1.5)),\n",
    "                    iaa.ClipCBAsToImagePlanes(),\n",
    "                ])\n",
    "\n",
    "        else:\n",
    "            scale = min(w / iw, h / ih)\n",
    "            self.seq = iaa.Sequential([\n",
    "                iaa.Resize(scale),\n",
    "                iaa.PadToFixedSize(width=w, height=h, pad_cval=128),\n",
    "                iaa.CropToFixedSize(width=w, height=h, position=\"center\"),\n",
    "            ])\n",
    "\n",
    "        # https://imgaug.readthedocs.io/en/latest/source/api_augmentables_bbs.html\n",
    "        bbs = BoundingBoxesOnImage.from_xyxy_array(boxes, (ih, iw))\n",
    "        image, bbs = self.seq(image=image, bounding_boxes=bbs)\n",
    "        \n",
    "        # to_xyxy_array(self[, dtype])\n",
    "        # Convert the BoundingBoxesOnImage object to an (N,4) ndarray.\n",
    "        boxes = bbs.to_xyxy_array()\n",
    "\n",
    "        hms = np.zeros((*self.output_shape, self.num_classes), np.float32)\n",
    "        whs = []\n",
    "        regs = []\n",
    "        reg_masks = []\n",
    "        indices = []\n",
    "\n",
    "        if len(boxes) != 0:\n",
    "            boxes = np.array(boxes[:, :4], dtype=np.float32)\n",
    "            boxes[:, [0, 2]] = np.clip(\n",
    "                boxes[:, [0, 2]] / self.input_shape[1] * self.output_shape[1],\n",
    "                0, self.output_shape[1] - 1)\n",
    "            boxes[:, [1, 3]] = np.clip(\n",
    "                boxes[:, [1, 3]] / self.input_shape[0] * self.output_shape[0],\n",
    "                0, self.output_shape[0] - 1)\n",
    "\n",
    "            for i in range(len(boxes)):\n",
    "                bbox = boxes[i].copy()\n",
    "                cls_id = cls_ids[i]\n",
    "\n",
    "                # Height, Width 설정\n",
    "                h, w = bbox[3] - bbox[1], bbox[2] - bbox[0]\n",
    "                if h > 0 and w > 0:\n",
    "                    radius = gaussian_radius((math.ceil(h), math.ceil(w)))\n",
    "                    radius = max(0, int(radius))\n",
    "                    #------------------------------------------------------------#\n",
    "                    #  Calculate the feature points to which the real box belongs\n",
    "                    #------------------------------------------------------------#\n",
    "                    ct = np.array([(bbox[0] + bbox[2]) / 2,\n",
    "                                   (bbox[1] + bbox[3]) / 2],\n",
    "                                  dtype=np.float32)\n",
    "                    ct_int = ct.astype(np.int32)\n",
    "                    #-----------------------------#\n",
    "                    #  plotting Gaussian heat map\n",
    "                    #-----------------------------#\n",
    "                    hms[:, :, cls_id] = draw_gaussian(hms[:, :, cls_id],\n",
    "                                                      ct_int, radius)\n",
    "                    #---------------------------------------------------#\n",
    "                    #   calculate the true value of width and height\n",
    "                    #---------------------------------------------------#\n",
    "                    whs.append([1. * w, 1. * h])\n",
    "                    #---------------------------------------------------#\n",
    "                    #   calculated center offset\n",
    "                    #---------------------------------------------------#\n",
    "                    regs.append(ct - ct_int)\n",
    "                    #---------------------------------------------------------#\n",
    "                    #  Set the corresponding mask to 1 to exclude the excess 0\n",
    "                    #---------------------------------------------------------#\n",
    "                    reg_masks.append(1)\n",
    "                    #----------------------------------------------------#\n",
    "                    #  Represents the number ct_int[0] in line ct_int[1]. \n",
    "                    #----------------------------------------------------#\n",
    "                    indices.append(ct_int[1] * self.output_shape[0] +\n",
    "                                   ct_int[0])\n",
    "        if not whs:\n",
    "            whs.append([0., 0.]) \n",
    "            regs.append([0., 0.])\n",
    "            reg_masks.append(0)\n",
    "            indices.append(0)\n",
    "\n",
    "        image = preprocess_input(image)\n",
    "        \n",
    "        whs = np.array(whs, np.float32)\n",
    "        regs = np.array(regs, np.float32)\n",
    "        reg_masks = np.array(reg_masks, np.int32)\n",
    "        indices = np.array(indices, np.int32)\n",
    "        \n",
    "\n",
    "        return image, boxes, cls_ids, hms, whs, regs, reg_masks, indices\n",
    "\n",
    "    def generate(self):\n",
    "        for i in range(len(self)):\n",
    "            yield self[i]\n",
    "\n",
    "    def load_dataset(self):\n",
    "        dataset = tf.data.Dataset.from_generator(self.generate,\n",
    "                                                 output_types=(\n",
    "                                                     tf.float32,\n",
    "                                                     tf.float32,\n",
    "                                                     tf.uint8,\n",
    "                                                     tf.float32,\n",
    "                                                     tf.float32,\n",
    "                                                     tf.float32,\n",
    "                                                     tf.int32,\n",
    "                                                     tf.int32,\n",
    "                                                 ))\n",
    "\n",
    "        if self.training:\n",
    "            dataset = dataset.shuffle(self.buffer_size * self.batch_size)\n",
    "\n",
    "        dataset = dataset.padded_batch(self.batch_size,\n",
    "                                       padded_shapes=((\n",
    "                                           *self.input_shape,\n",
    "                                           3,\n",
    "                                       ), (\n",
    "                                           None,\n",
    "                                           4,\n",
    "                                       ), (None, ), (\n",
    "                                           *self.output_shape,\n",
    "                                           self.num_classes,\n",
    "                                       ), (None, 2), (None, 2), (None, ),\n",
    "                                                      (None, )))\n",
    "\n",
    "        def orginize(image, boxes, cls_ids, hms, whs, regs, reg_masks,\n",
    "                      indices):\n",
    "            image.set_shape([self.batch_size, *self.input_shape, 3])\n",
    "            boxes.set_shape([self.batch_size, None, 4])\n",
    "            cls_ids.set_shape([self.batch_size, None])\n",
    "            hms.set_shape([self.batch_size, *self.output_shape, self.num_classes])\n",
    "            whs.set_shape([self.batch_size, None, 2])\n",
    "            regs.set_shape([self.batch_size, None, 2])\n",
    "            reg_masks.set_shape([self.batch_size, None])\n",
    "            indices.set_shape([self.batch_size, None])\n",
    "\n",
    "            return {\n",
    "                \"images\": image,\n",
    "            }, {\n",
    "                \"boxes\": boxes,\n",
    "                \"cls_ids\": cls_ids,\n",
    "                \"hms\": hms,\n",
    "                \"whs\": whs,\n",
    "                \"regs\": regs,\n",
    "                \"reg_masks\": reg_masks,\n",
    "                \"indices\": indices\n",
    "            }\n",
    "\n",
    "        dataset = dataset.map(orginize)\n",
    "\n",
    "        if self.training:\n",
    "            dataset = dataset.prefetch(\n",
    "                buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "        return dataset"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "de54506a83f8ee6b284703bffbec36bf2dd70efd52509c97f7e6dc01858c1532"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
